# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XUqRMKqnZ8AwJpE1Htm-0Uo83zk6U0tF
"""

# #1 Generic Algorithm for Feature Selection: 2. Binary

import numpy as np #numeryczna bibl. zawiera takie operacje jak obłsuga macierzy etc.
                   # numpy -> operator zasięgu, zasada liskow: .
import pandas as pd # bibloteak która zawiera narzędzia do manipulacji danymi
import seaborn as sns  # biblioteka do statystycznej wizualziacji
from random import randint # biblioteka zawierająca algorytmy pseudo-losowe

import warnings # bib. bledow, obsluga bledow -> kategoryzacjia: log, warrnigs, error etc.

# kFold -> cross_validacja
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.model_selection import KFold, cross_val_score #Genetic aglrotrhm #bibloteka do analizy danch
from sklearn.metrics import accuracy_score

#  Gentic algorithm:
#1. Start
#2. Inicjalizacja populacji dla generacji = 0
#3. Evaluacja: dopasowanie objectives
#4. Sprawdzenie warunków spełnialności: (kiedy zakończyć działanie)
#  4.1 if: TRUE: kończymy
#  4.2 else: Wybranie najlepszego rodzica
#  4.3       Cros-over
#  4.5       Mutate
#  4.6       Stworzenie populacji dla generacji + 1
#  4.7       Back -> 4

# Problem: znajdowanie najlepszych cech (features/inputs)
'''
# mutation
#  Parent1 = 1,2,3,7
  Mutation =  1,5,3,7
# crossover (one Point)
  Parent1 = 1,2,3,7
  Parent2 = 4,9,8,6
  Res = 1,2, 8,6
Multi Point
   Res = 1,9,3,6
# selection: Rank Selection: fintess
'''

logmodel = RandomForestClassifier(n_estimators=200, random_state=0)
data_df = pd.read_csv("") # TODO: znajdz data set
label = data_df[""] # wyciagniecie danych
X_train, X_test, Y_train, Y_test = train_test_split(data_df, label, test_size=0.2, random_state=4)

# Stworzenie randomowej populacji
def init_population(size_of_population, shape_of_chromosome):
    population = []
    for i in range(size_of_population):
        chromosome = np.ones(shape=shape_of_chromosome, dtype=np.bool) ## data type: bool, binnary type
        chromosome[:int(0.4*shape_of_chromosome)] = False# <x...,N>
        np.random.shuffle(chromosome)
        population.append(chromosome)
    return population

# RandomForest

def fitness_score(population):
    score_result = []
    for chromosome in population:
        # Datasets: Train, Valid, Test: Train i Valid: ten sam zbiór (20%->vALID):
        logmodel.fit(X_train.iloc[:chromosome], Y_train) #training #Y_train -> labels, X_train: dane
        prediction = logmodel.predict() #Wrzucenie danyuch testowych.
        score_result.append(accuracy_score(Y_test, prediction)) #wartosć: 0,1
    score_result, population = np.array(score_result), np.array(population)
    indicator = np.argsort(score_result) # x1 >= x2 >= x3 >= .... >= xn, gdzie n - to jest liczba danych I/O
    return list(score_result[indicator][::-1]), list(population[indicator,::][::-1])

def selection(population_fitness_score, number_of_parrents):
  population_next_generation = []
  #population_next_generation = [population_fitness_score[item] for item in range(number_of_parrents)]
  for i in range(number_of_parrents):
    population_next_generation.append(population_fitness_score[i])
  return population_next_generation

def crossover(population_selection_fit): # one-point-method
  population_next_generation = population_selection_fit
  for i in range(0, len(population_selection_fit), 2):
    new_parrent = []
    child_st, child_nd = population_next_generation[i], population_next_generation[i + 1]
    new_parrent = np.concatenate((child_st[:len(child_st)//2],child_nd[len(child_st)//2:]))
    population_next_generation.append(new_parrent)
  return population_next_generation

def mutation(population_cross, mutation_rate, feat):
    mutation_range = int(mutation_rate*feat)
    pop_next_gen = []
    for n in range(0,len(population_cross)):
        chromosome = population_cross[n]
        rand_posi = []
        for i in range(0,mutation_range):
            pos = randint(0,feat-1)
            rand_posi.append(pos)
        for j in rand_posi:
            chromosome[j] = not chromosome[j]
        pop_next_gen.append(chromosome)
    return pop_next_gen

# Data Structure: Letcode! Algorytm
#Vector, Tablice, Drzewa, HashMap: SQL (DS), BigData(obsludze dużych danch, Haddop, Spark, Hive)
# Hive->SQL, Releacyjne,
# Funkcja, która będzie sklejała, zawiera runner's wszyskich funkcji naszego GA's algo
def generation(data, lables, size_of_population, shape_of_chromosome, number_of_generation, number_of_parents, feat):
    population_next_generation = init_population(size_of_population, shape_of_chromosome)
    best_chrom_result = []
    best_score_result = []
    for i in range(number_of_generation):
        score, population_fitness = fitness_score(population_next_generation) # 1
        print('Najlepszy rezultat', i + 1, ":", score[:1]) # 2
        population_selection = selection(population_fitness, number_of_parents)
        population_crossover = crossover(population_selection)
        population_next_generation = mutation(population_crossover, feat)
        best_chrom_result.append(population_fitness[0])
        best_score_result.append(score[0])
    return best_chrom_result, best_score_result


# RUN :D
from sklearn.model_selection import train_test_split
def main():
  chrosome_best_res, best_score_result = generation(data = data_df,
                                                    labels = label,
                                                    size_of_population = 80,
                                                    shape_of_chromosome = 3,
                                                    feat=data_df.shape[1],
                                                    number_of_parents=64,
                                                    number_of_generation=5)
  generation();

if __name__ == "__main__":
  main()





# 3 TSP: Permutation

import numpy as np #numeryczna bibl. zawiera takie operacje jak obłsuga macierzy etc.
                   # numpy -> operator zasięgu, zasada liskow: .
import pandas as pd # bibloteak która zawiera narzędzia do manipulacji danymi
import seaborn as sns  # biblioteka do statystycznej wizualziacji
from random import randint # biblioteka zawierająca algorytmy pseudo-losowe

import warnings # bib. bledow, obsluga bledow -> kategoryzacjia: log, warrnigs, error etc.

# kFold -> cross_validacja
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.model_selection import KFold, cross_val_score #Genetic aglrotrhm #bibloteka do analizy danch
from sklearn.metrics import accuracy_score



import random as rand
import numpy.random as rand_2
CITIES_DISTANCE = []

# permutation
def init_population(size_of_population):
    size_of_distance = len(CITIES_DISTANCE)
    chromosome = []
    for i in range(size_of_distance):
        chromosome.append(i)
    population = [chromosome.copy() for _ in range(size_of_population)]

    for i in range(size_of_population):
      unique_chromosome = population[i]
      # swap, 2 losowych miast n times in each chromosme
      for j in range(len(unique_chromosome)):
        rnd_city_st = rand.randrange(0, len(unique_chromosome))
        rnd_city_nd = rand.randrange(0, len(unique_chromosome))
        unique_chromosome[rnd_city_st], unique_chromosome[rnd_city_nd] = unique_chromosome[rnd_city_nd],unique_chromosome[rnd_city_st]
    return population

# calculate distance in a chromosome: u -> v
# macierz sasiedctwa
#[ 0 1 2 3
#0 1 0
#1
#2
#3
#]
#0-1 DFS, 0-1 Dijkstra:
def total_distance(population): # DFS () + 1
  total_distance = 0
  previous_city = population[0]
  for city in population[1:]:
    if CITIES_DISTANCE[previous_city][city] is not None:
      total_distance = total_distance + CITIES_DISTANCE[previous_city][city]
    else:
      total_distance = total_distance + CITIES_DISTANCE[city][previous_city]
    previous_city = city
  return total_distance

def fitness_score(population):
  total_distance_temp = total_distance(population)
  return 1 / total_distance_temp;

def select(population, calculated_fitness):
  fitness_val = [fitness_score(i) for i in population]
  sum_fitness = sum(fitness_val)
  sel = [fitness_val[index] / sum_fitness for index, _ in enumerate(population)]
  population_idx = [ind for ind in range(len(population))]
  sel_ind_index = rand_2.choice(population_idx, p = sel)
  return population[sel_ind_index]

def repr(x, y):
  n = len(x)
  child = [None] * n
  rnd_index_st, rnd_index_nd = rand.randrange(0, n), rand.range(0, n)
  subseq_beg, subseq_end = min(rnd_index_st, rnd_index_nd), max(rnd_index_st, rnd_index_nd);
  # <min, max>
  for i in range(subseq_beg, subseq_end):
    child[i] = x[i]
  y_rem = [city for city in y if city not in child]
  none_index = [index for index, _ in enumerate(child) if city is None]
  for i, city in zip(none_index, y_rem):
    if child[i] is None:
      child[i] = city
  return child

def mutate(child):
  new_child = child.copy()
  n = len(child)
  rnd_index_st, rnd_index_nd = rand.randrange(0, n), rand.range(0, n)
  new_child[rnd_index_st], new_child[rnd_index_nd] = child[rnd_index_nd], new_child[rnd_index_st]
  return new_child

def search(population, cal_fitness, generation = 50):
  for _ in range(generation):
    new_population = []
    for _ in range(len(population)):
      x = select(population, cal_fitness)
      y = select(population, cal_fitness)
      child = repr(x, y)
      if (rand.unifrom(0, 1) <= 0.1):
        child = mutate(child)
      new_population.append(child)
    population = new_population
  return max(population, key=cal_fitness)

# RUN
init_population(4)